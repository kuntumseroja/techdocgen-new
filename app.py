"""
Modern Web UI for Technical Documentation Generator
Built with Streamlit
"""

import streamlit as st
import os
import sys
import re
from pathlib import Path
from typing import Optional, List, Dict, Any
import tempfile
import shutil
import requests
from datetime import datetime
import textwrap

try:
    import streamlit_mermaid as stmd
    MERMAID_AVAILABLE = True
except ImportError:
    MERMAID_AVAILABLE = False

# Add src to path
sys.path.insert(0, str(Path(__file__).parent))

try:
    from src.generator import DocumentationGenerator
    from src.config import Config
    from src.pdf_generator import PDFGenerator
    from src.correlation_analyzer import build_correlation_signals
except ImportError as e:
    st.error(f"Import error: {e}. Make sure all dependencies are installed.")
    st.stop()

# Page configuration
st.set_page_config(
    page_title="TechDocGen by IBMC - Technical Documentation Generator",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for modern UI
st.markdown("""
<style>
    .logo-container {
        display: flex;
        align-items: center;
        gap: 1rem;
        margin-bottom: 1rem;
    }
    .logo-img {
        height: 50px;
        width: auto;
    }
    .main-header {
        font-size: 3rem;
        font-weight: 700;
        background: linear-gradient(90deg, #0066CC 0%, #004499 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 0.5rem;
    }
    .brand-tagline {
        color: #0066CC;
        font-size: 0.9rem;
        font-weight: 500;
        margin-top: -0.5rem;
        margin-bottom: 0.5rem;
    }
    .sub-header {
        color: #6b7280;
        font-size: 1.1rem;
        margin-bottom: 2rem;
    }
    .stButton>button {
        width: 100%;
        background: linear-gradient(90deg, #0066CC 0%, #004499 100%);
        color: white;
        font-weight: 600;
        border: none;
        border-radius: 0.5rem;
        padding: 0.75rem 1.5rem;
        transition: all 0.3s;
    }
    .stButton>button:hover {
        transform: translateY(-2px);
        box-shadow: 0 10px 20px rgba(0, 102, 204, 0.3);
    }
    .info-box {
        background: linear-gradient(135deg, #0066CC15 0%, #00449915 100%);
        padding: 1.5rem;
        border-radius: 0.75rem;
        border-left: 4px solid #0066CC;
        margin: 1rem 0;
    }
    .success-box {
        background: linear-gradient(135deg, #10b98115 0%, #05966915 100%);
        padding: 1.5rem;
        border-radius: 0.75rem;
        border-left: 4px solid #10b981;
        margin: 1rem 0;
    }
    .metric-card {
        background: white;
        padding: 1.5rem;
        border-radius: 0.75rem;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        border: 1px solid #e5e7eb;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'generated_docs' not in st.session_state:
    st.session_state.generated_docs = None
if 'generation_status' not in st.session_state:
    st.session_state.generation_status = None
if 'dependency_analysis' not in st.session_state:
    st.session_state.dependency_analysis = None
if 'dependency_map_data' not in st.session_state:
    st.session_state.dependency_map_data = None
if 'source_files' not in st.session_state:
    st.session_state.source_files = None

def load_config():
    """Load configuration"""
    config_path = st.session_state.get('config_path', 'config.yaml')
    try:
        return Config(config_path)
    except:
        return Config()

def get_ollama_models(base_url: str = "http://localhost:11434") -> List[str]:
    """Fetch available Ollama models from the API"""
    try:
        response = requests.get(f"{base_url}/api/tags", timeout=5)
        if response.status_code == 200:
            data = response.json()
            models = [model.get("name", "") for model in data.get("models", [])]
            return sorted(models) if models else []
    except (requests.exceptions.RequestException, KeyError):
        pass
    return []

def extract_project_title(source_path: Optional[str], source_type: Optional[str]) -> str:
    """Extract project title from source path"""
    if not source_path:
        return "Technical_Documentation"
    
    try:
        title = ""
        if source_type == "Single File":
            # Use filename without extension
            title = Path(source_path).stem
        elif source_type == "Folder":
            # Use folder name
            title = Path(source_path).name
        elif source_type == "Git Repository":
            # Extract repo name from URL or path
            if source_path.startswith(('http://', 'https://')):
                # Extract from URL like https://github.com/user/repo.git
                repo_name = source_path.rstrip('/').rstrip('.git').split('/')[-1]
                title = repo_name
            else:
                # Local git path
                title = Path(source_path).name
        else:
            title = Path(source_path).stem if source_path else "Technical_Documentation"
        
        # Sanitize filename: remove invalid characters
        title = re.sub(r'[<>:"/\\|?*]', '_', title)
        title = title.replace(' ', '_')
        return title if title else "Technical_Documentation"
    except:
        return "Technical_Documentation"

def generate_summary(docs: str) -> str:
    """Extract or generate a summary from the documentation"""
    if not docs:
        return "No summary available."
    
    # Try to extract the first meaningful paragraph after the title
    lines = docs.split('\n')
    summary_lines = []
    found_content = False
    
    for i, line in enumerate(lines):
        # Skip title and metadata lines
        if line.strip().startswith('#') and 'Technical Documentation' in line:
            continue
        if 'Generated using' in line:
            continue
        if line.strip() == '---':
            continue
        if not line.strip():
            if found_content:
                break
            continue
        
        # Start collecting summary after skipping header
        if not found_content and line.strip():
            found_content = True
        
        if found_content:
            # Stop at first heading or after 3-4 sentences
            if line.strip().startswith('##'):
                break
            summary_lines.append(line.strip())
            if len(summary_lines) >= 4 and any(line.strip().endswith('.') for line in summary_lines[-3:]):
                break
    
    summary = ' '.join(summary_lines).strip()
    
    # If no good summary found, create a basic one
    if not summary or len(summary) < 50:
        # Count files and languages
        file_count = docs.count('### ')  # Count file sections
        languages = set()
        for lang in ['java', 'csharp', 'vbnet', 'fsharp', 'php']:
            if f'{lang.upper()} Files' in docs:
                languages.add(lang)
        
        summary = f"This documentation covers {file_count} source file(s) "
        if languages:
            summary += f"written in {', '.join(languages)}. "
        summary += "The documentation includes detailed explanations of classes, methods, and code structure."
    
    return summary

def sanitize_mermaid_node_id(path: str) -> str:
    """
    Sanitize a file path to create a valid Mermaid node ID.
    Mermaid node IDs must start with a letter or underscore and can contain letters, numbers, and underscores.
    """
    # Convert path to a safe identifier
    # Replace path separators, dots, spaces, and other special chars with underscores
    node_id = re.sub(r'[^\w]', '_', str(path))
    # Remove consecutive underscores
    node_id = re.sub(r'_+', '_', node_id)
    # Remove leading/trailing underscores
    node_id = node_id.strip('_')
    # Ensure it starts with a letter or underscore (Mermaid requirement)
    if node_id and not node_id[0].isalpha() and node_id[0] != '_':
        node_id = '_' + node_id
    # Limit length to avoid issues
    return node_id[:50] if node_id else 'node'


def sanitize_mermaid_label(text: str) -> str:
    """
    Sanitize text for use in Mermaid node labels.
    Escapes quotes and other special characters that might break Mermaid syntax.
    """
    # Escape quotes and backslashes
    label = text.replace('\\', '\\\\').replace('"', '\\"')
    # Remove or replace newlines
    label = label.replace('\n', ' ').replace('\r', ' ')
    # Limit length
    return label[:40] if label else 'file'


def render_markdown_with_mermaid(content: str):
    """Render markdown content, extracting and rendering Mermaid diagrams separately"""
    # Split content by Mermaid code blocks
    pattern = r'(```mermaid.*?```)'
    parts = re.split(pattern, content, flags=re.DOTALL)
    
    for part in parts:
        if part.strip().startswith('```mermaid'):
            # Extract Mermaid diagram code
            diagram_code = re.sub(r'```mermaid\s*', '', part)
            diagram_code = re.sub(r'```\s*$', '', diagram_code, flags=re.MULTILINE)
            # Clean up: remove leading/trailing whitespace and normalize line endings
            diagram_code = diagram_code.strip()
            # Normalize indentation for Mermaid parser
            diagram_code = textwrap.dedent(diagram_code).strip()
            # Remove any empty lines at start/end
            lines = [line for line in diagram_code.split('\n') if line.strip() or len([l for l in diagram_code.split('\n') if l.strip()]) > 0]
            diagram_code = '\n'.join(lines).strip()
            
            # Render Mermaid diagram as SVG
            if MERMAID_AVAILABLE:
                try:
                    stmd.st_mermaid(diagram_code)
                except Exception as e:
                    # Show error and fallback to code block
                    st.warning(f"‚ö†Ô∏è Could not render diagram: {str(e)}")
                    with st.expander("View diagram code"):
                        st.code(diagram_code, language="mermaid")
            else:
                # Fallback: show as code block with note
                st.info("üí° Install streamlit-mermaid to view diagrams: `pip install streamlit-mermaid`")
                st.code(diagram_code, language="mermaid")
        else:
            # Regular markdown content
            if part.strip():
                st.markdown(part)

def main():
    # Header with IBMC branding
    logo_path = Path(__file__).parent / "assets" / "ibmc-logo.svg"
    
    # Create header with logo and branding
    header_col1, header_col2 = st.columns([1, 5])
    with header_col1:
        if logo_path.exists():
            with open(logo_path, 'r') as f:
                logo_svg = f.read()
            # Adjust logo size for header
            logo_svg = logo_svg.replace('width="120" height="40"', 'width="80" height="30"')
            st.markdown(logo_svg, unsafe_allow_html=True)
        else:
            st.markdown('<div style="font-size: 2rem; font-weight: bold; color: #0066CC;">IBMC</div>', unsafe_allow_html=True)
    
    with header_col2:
        st.markdown('<h1 class="main-header">TechDocGen</h1>', unsafe_allow_html=True)
        st.markdown('<p class="brand-tagline">by IBMC</p>', unsafe_allow_html=True)
    
    st.markdown('<p class="sub-header">Generate comprehensive technical documentation from your source code using AI</p>', unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.markdown("### ‚öôÔ∏è Configuration")
        
        # LLM Provider Selection
        config = load_config()
        available_providers = ['ollama', 'mcp']
        default_provider = config.get_default_provider()
        
        selected_provider = st.selectbox(
            "ü§ñ LLM Provider",
            available_providers,
            index=available_providers.index(default_provider) if default_provider in available_providers else 0,
            help="Choose the LLM provider to generate documentation"
        )

        doc_structures_dir = Path(__file__).parent / "doc_structures"
        doc_structure_options = ["Default (file-centric)"]
        if doc_structures_dir.exists():
            doc_structure_options.extend(
                sorted(p.stem for p in doc_structures_dir.glob("*.yaml"))
            )
        selected_doc_structure = st.selectbox(
            "üß± Document Structure",
            options=doc_structure_options,
            index=0,
            help="Choose an architecture-centric structure or use the default file-centric output"
        )
        st.session_state.doc_structure = None if selected_doc_structure == "Default (file-centric)" else selected_doc_structure
        
        # Provider-specific settings
        if selected_provider == 'ollama':
            st.markdown("#### Ollama Settings")
            ollama_url = st.text_input(
                "Base URL",
                value=os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
                help="Ollama server URL"
            )
            
            # Get available models from Ollama
            available_models = get_ollama_models(ollama_url)
            
            # Get default model from config or env
            config_ollama = config.config.get("llm_providers", {}).get("ollama", {})
            default_model = os.getenv("OLLAMA_MODEL", config_ollama.get("model", "llama3.2"))
            
            if available_models:
                # Show dropdown with available models
                if default_model in available_models:
                    default_index = available_models.index(default_model)
                else:
                    default_index = 0
                
                ollama_model = st.selectbox(
                    "Model",
                    options=available_models,
                    index=default_index,
                    help="Select an Ollama model. Make sure Ollama is running and the model is pulled."
                )
                
                # Show refresh button to reload models
                if st.button("üîÑ Refresh Models", use_container_width=True, help="Reload available models from Ollama"):
                    st.rerun()
            else:
                # Fallback to text input if models can't be fetched
                st.warning("‚ö†Ô∏è Could not fetch models from Ollama. Make sure Ollama is running.")
                ollama_model = st.text_input(
                    "Model",
                    value=default_model,
                    help="Enter Ollama model name manually (e.g., deepseek-coder:6.7b). Make sure the model is pulled: ollama pull <model-name>"
                )
                if st.button("üîÑ Refresh Models", use_container_width=True, help="Try to reload available models"):
                    st.rerun()
            
            # Store in session state for use during generation
            st.session_state.ollama_url = ollama_url
            st.session_state.ollama_model = ollama_model
        
        st.markdown("---")
        
        # Advanced Settings
        with st.expander("üîß Advanced Settings"):
            max_file_size = st.number_input(
                "Max File Size (MB)",
                min_value=1,
                max_value=100,
                value=10,
                help="Maximum file size to process"
            )
            
            include_comments = st.checkbox("Include Comments", value=True)
            include_imports = st.checkbox("Include Imports", value=True)
    
    # Main content area
    tab1, tab2, tab3, tab4 = st.tabs(["üìÅ Source Selection", "‚ö° Generate", "üìÑ Preview", "üîó Correlation & Dependencies"])
    
    with tab1:
        st.markdown("### Select Source Code")
        
        source_type = st.radio(
            "Source Type",
            ["Single File", "Folder", "Git Repository"],
            horizontal=True,
            help="Choose the type of source to document"
        )
        
        source_path = None
        
        if source_type == "Single File":
            uploaded_file = st.file_uploader(
                "Upload a source file",
                type=['java', 'cs', 'vb', 'fs', 'fsx', 'cshtml', 'vbhtml', 'php'],
                help="Upload a Java, .NET (C#, VB.NET, F#), or PHP file"
            )
            if uploaded_file:
                # Save uploaded file temporarily
                temp_dir = Path(tempfile.mkdtemp())
                source_path = str(temp_dir / uploaded_file.name)
                with open(source_path, 'wb') as f:
                    f.write(uploaded_file.getbuffer())
                st.session_state.temp_source_path = source_path
                st.success(f"‚úÖ File uploaded: {uploaded_file.name}")
        
        elif source_type == "Folder":
            folder_path = st.text_input(
                "Folder Path",
                placeholder="/path/to/your/project",
                help="Enter the path to your project folder"
            )
            if folder_path and Path(folder_path).exists():
                source_path = folder_path
                st.success(f"‚úÖ Folder found: {folder_path}")
            elif folder_path:
                st.error(f"‚ùå Folder not found: {folder_path}")
        
        elif source_type == "Git Repository":
            git_url = st.text_input(
                "Git Repository URL",
                placeholder="https://github.com/user/repo.git",
                help="Enter Git repository URL or local path"
            )
            branch = st.text_input(
                "Branch (optional)",
                placeholder="main",
                help="Specify branch to use"
            )
            if git_url:
                source_path = git_url
                st.session_state.git_branch = branch if branch else None
                st.info(f"üì¶ Repository: {git_url}")
    
    with tab2:
        st.markdown("### Generate Documentation")
        
        if source_path:
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.info(f"üìÇ Source: {source_path}")
                if source_type == "Git Repository" and st.session_state.get('git_branch'):
                    st.info(f"üåø Branch: {st.session_state.git_branch}")
            
            with col2:
                generate_btn = st.button("üöÄ Generate Documentation", type="primary", use_container_width=True)
            
            if generate_btn:
                # Store source info in session state
                st.session_state.source_path = source_path
                st.session_state.source_type = source_type
                
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # Store original environment variables for restoration
                original_ollama_model = None
                original_ollama_url = None
                
                try:
                    status_text.text("üîÑ Initializing generator...")
                    progress_bar.progress(10)
                    
                    # Update config with UI-selected Ollama settings if applicable
                    if selected_provider == 'ollama' and st.session_state.get('ollama_model'):
                        # Temporarily set environment variables to override config
                        original_ollama_model = os.getenv("OLLAMA_MODEL")
                        original_ollama_url = os.getenv("OLLAMA_BASE_URL")
                        os.environ["OLLAMA_MODEL"] = st.session_state.ollama_model
                        if st.session_state.get('ollama_url'):
                            os.environ["OLLAMA_BASE_URL"] = st.session_state.ollama_url
                    
                    # Initialize generator
                    generator = DocumentationGenerator(llm_provider=selected_provider)
                    
                    status_text.text("üìñ Reading source code...")
                    progress_bar.progress(10)
                    
                    # Read source files first
                    if source_type == "Single File":
                        from src.readers import FileReader
                        reader = FileReader(source_path, generator.config.config)
                        files = reader.read()
                    elif source_type == "Folder":
                        from src.readers import FolderReader
                        reader = FolderReader(source_path, generator.config.config)
                        files = reader.read()
                    elif source_type == "Git Repository":
                        from src.readers import GitReader
                        branch = st.session_state.get('git_branch')
                        reader = GitReader(source_path, branch, generator.config.config)
                        files = reader.read()
                    
                    # Store files in session state for dependency analysis
                    st.session_state.source_files = files
                    
                    total_files = len(files)
                    progress_bar.progress(20)
                    status_text.text(f"‚úÖ Found {total_files} file(s). Starting AI documentation generation...")
                    
                    # Progress callback for file processing
                    file_status = st.empty()
                    
                    def update_progress(current, total, filename):
                        progress_pct = 20 + int((current / total) * 70)  # 20-90% range
                        progress_bar.progress(progress_pct)
                        file_status.text(f"ü§ñ Processing file {current}/{total}: {filename}")
                    
                    # Generate documentation with progress tracking
                    doc_structure = st.session_state.get("doc_structure")
                    if doc_structure:
                        docs = generator.generate_architecture_docs_from_files(
                            files,
                            doc_structure_name=doc_structure,
                            progress_callback=update_progress
                        )
                    elif source_type == "Single File":
                        docs = generator.generate_from_file(source_path, update_progress)
                    elif source_type == "Folder":
                        docs = generator.generate_from_folder(source_path, update_progress)
                    elif source_type == "Git Repository":
                        branch = st.session_state.get('git_branch')
                        docs = generator.generate_from_git(source_path, branch, update_progress)
                    
                    file_status.empty()
                    status_text.text("‚úÖ Documentation generation complete!")
                    progress_bar.progress(90)
                    
                    # Save to session state
                    st.session_state.generated_docs = docs
                    st.session_state.generation_status = "success"
                    
                    status_text.text("üíæ Saving documentation...")
                    progress_bar.progress(90)
                    
                    # Save to file
                    output_file = generator.save_documentation(docs)
                    st.session_state.output_file = str(output_file)
                    
                    progress_bar.progress(100)
                    status_text.text("‚úÖ Complete!")
                    
                    st.success("‚úÖ Documentation generated successfully!")
                    st.balloons()
                    
                    # Cleanup temp files if any
                    if source_type == "Single File" and st.session_state.get('temp_source_path'):
                        temp_path = Path(st.session_state.temp_source_path)
                        if temp_path.exists():
                            try:
                                shutil.rmtree(temp_path.parent)
                            except:
                                pass
                    
                except Exception as e:
                    progress_bar.progress(0)
                    status_text.text("‚ùå Error occurred")
                    st.error(f"‚ùå Error: {str(e)}")
                    st.session_state.generation_status = "error"
                    st.session_state.error_message = str(e)
                    
                    # Show detailed error in expander
                    with st.expander("üîç Error Details"):
                        import traceback
                        st.code(traceback.format_exc())
                finally:
                    # Restore original environment variables
                    if selected_provider == 'ollama':
                        if original_ollama_model is None:
                            os.environ.pop("OLLAMA_MODEL", None)
                        else:
                            os.environ["OLLAMA_MODEL"] = original_ollama_model
                        if original_ollama_url is None:
                            os.environ.pop("OLLAMA_BASE_URL", None)
                        else:
                            os.environ["OLLAMA_BASE_URL"] = original_ollama_url
        else:
            st.warning("‚ö†Ô∏è Please select a source in the 'Source Selection' tab first.")
    
    with tab3:
        st.markdown("### Preview & Download")
        
        if st.session_state.generated_docs:
            # Get project title and date for PDF filename
            source_path = st.session_state.get('source_path')
            source_type = st.session_state.get('source_type')
            project_title = extract_project_title(source_path, source_type)
            current_date = datetime.now().strftime("%d-%m-%Y")
            pdf_filename = f"{project_title}_{current_date}.pdf"
            
            # Summary Section
            st.markdown("#### üìã Summary")
            summary = generate_summary(st.session_state.generated_docs)
            st.info(summary)
            
            # Source Files List
            if st.session_state.get('source_files'):
                st.markdown("#### üìÅ Source Files")
                files = st.session_state.source_files
                
                # Group files by language
                files_by_lang = {}
                for file_info in files:
                    lang = file_info.get('language', 'unknown')
                    if lang not in files_by_lang:
                        files_by_lang[lang] = []
                    files_by_lang[lang].append(file_info)
                
                # Display files in expandable sections by language
                for lang, lang_files in sorted(files_by_lang.items()):
                    if lang == 'unknown':
                        continue
                    with st.expander(f"{lang.upper()} Files ({len(lang_files)})", expanded=False):
                        for file_info in lang_files:
                            file_path = file_info.get('relative_path') or file_info.get('path', 'Unknown')
                            file_name = file_info.get('name', Path(file_path).name)
                            st.text(f"‚Ä¢ {file_name}")
                            st.caption(f"  {file_path}")
            
            st.markdown("---")
            
            # Metrics
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Status", "‚úÖ Ready")
            with col2:
                doc_length = len(st.session_state.generated_docs)
                st.metric("Documentation Size", f"{doc_length:,} chars")
            with col3:
                lines = st.session_state.generated_docs.count('\n')
                st.metric("Lines", f"{lines:,}")
            with col4:
                if st.session_state.get('output_file'):
                    st.metric("Saved To", "‚úÖ Yes")
            
            # Download buttons
            col1, col2 = st.columns(2)
            
            with col1:
                st.download_button(
                    label="üì• Download Markdown",
                    data=st.session_state.generated_docs,
                    file_name="technical_documentation.md",
                    mime="text/markdown",
                    use_container_width=True
                )
            
            with col2:
                pdf_error = None
                if 'pdf_generator' not in st.session_state:
                    try:
                        st.session_state.pdf_generator = PDFGenerator()
                    except Exception as e:
                        pdf_error = e
                
                if pdf_error:
                    st.warning("‚ö†Ô∏è PDF generation is unavailable in this environment.")
                    st.info("üí° Install dependencies: `pip install -r requirements.txt`")
                    with st.expander("üîç Error Details"):
                        st.code(str(pdf_error))
                else:
                    try:
                        pdf_bytes = st.session_state.pdf_generator.generate_pdf_from_markdown(
                            st.session_state.generated_docs
                        )
                        st.download_button(
                            label="üìÑ Download PDF (Confluence Style)",
                            data=pdf_bytes.getvalue(),
                            file_name=pdf_filename,
                            mime="application/pdf",
                            use_container_width=True
                        )
                    except Exception as e:
                        st.error(f"‚ùå PDF generation failed: {str(e)}")
                        st.info("üí° Make sure all dependencies are installed: `pip install -r requirements.txt`")
                        with st.expander("üîç Error Details"):
                            import traceback
                            st.code(traceback.format_exc())
            
            st.markdown("---")
            
            # Preview
            st.markdown("### Preview")
            with st.expander("üìñ View Full Documentation", expanded=True):
                # Render markdown with Mermaid diagrams
                render_markdown_with_mermaid(st.session_state.generated_docs)
        else:
            st.info("üëÜ Generate documentation first to see preview here.")
    
    with tab4:
        st.markdown("### üîó Correlation & Dependency Analysis")
        
        if st.session_state.source_files and len(st.session_state.source_files) > 0:
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.info(f"üìÇ {len(st.session_state.source_files)} file(s) available for analysis")
            
            with col2:
                analyze_btn = st.button("üîç Analyze Dependencies", type="primary", use_container_width=True, key="analyze_deps")
            
            if analyze_btn:
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # Store original environment variables for restoration
                original_ollama_model = None
                original_ollama_url = None
                
                try:
                    status_text.text("üîÑ Initializing dependency analyzer...")
                    progress_bar.progress(10)
                    
                    # Update config with UI-selected Ollama settings if applicable
                    if selected_provider == 'ollama' and st.session_state.get('ollama_model'):
                        # Temporarily set environment variables to override config
                        original_ollama_model = os.getenv("OLLAMA_MODEL")
                        original_ollama_url = os.getenv("OLLAMA_BASE_URL")
                        os.environ["OLLAMA_MODEL"] = st.session_state.ollama_model
                        if st.session_state.get('ollama_url'):
                            os.environ["OLLAMA_BASE_URL"] = st.session_state.ollama_url
                    
                    # Initialize generator
                    generator = DocumentationGenerator(llm_provider=selected_provider)
                    
                    status_text.text("üìä Analyzing dependencies...")
                    progress_bar.progress(30)
                    
                    # Analyze dependencies
                    analysis = generator.dependency_analyzer.analyze_files(
                        st.session_state.source_files, 
                        generator.parsers
                    )
                    
                    progress_bar.progress(80)
                    status_text.text("‚úÖ Analysis complete!")
                    
                    # Store in session state
                    st.session_state.dependency_analysis = analysis
                    st.session_state.dependency_map_data = generator.dependency_analyzer._build_dependency_map()
                    st.session_state.dependency_analyzer = generator.dependency_analyzer
                    
                    progress_bar.progress(100)
                    status_text.text("‚úÖ Ready!")
                    
                    st.success("‚úÖ Dependency analysis complete!")
                    st.rerun()
                    
                except Exception as e:
                    progress_bar.progress(0)
                    status_text.text("‚ùå Error occurred")
                    st.error(f"‚ùå Error: {str(e)}")
                    with st.expander("üîç Error Details"):
                        import traceback
                        st.code(traceback.format_exc())
                finally:
                    # Restore original environment variables
                    if selected_provider == 'ollama':
                        if original_ollama_model is None:
                            os.environ.pop("OLLAMA_MODEL", None)
                        else:
                            os.environ["OLLAMA_MODEL"] = original_ollama_model
                        if original_ollama_url is None:
                            os.environ.pop("OLLAMA_BASE_URL", None)
                        else:
                            os.environ["OLLAMA_BASE_URL"] = original_ollama_url
            
            # Display analysis results
            if st.session_state.dependency_analysis:
                analysis = st.session_state.dependency_analysis
                dep_map = st.session_state.dependency_map_data
                
                # Correlation Focus
                st.markdown("#### üîç Cross-Stack Correlation (C#/.NET, RabbitMQ/MassTransit, Node.js, Angular)")
                correlation = build_correlation_signals(st.session_state.source_files, dep_map)
                csharp_messaging = correlation.get("csharp_messaging", [])
                node_messaging = correlation.get("node_messaging", [])
                angular_files = correlation.get("angular_files", [])
                cross_stack = "Detected" if csharp_messaging and node_messaging else "Not detected"

                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric(".NET Messaging Files", len(csharp_messaging))
                with col2:
                    st.metric("Node.js Messaging Files", len(node_messaging))
                with col3:
                    st.metric("Angular Files", len(angular_files))
                with col4:
                    st.metric("Cross-Stack Signal", cross_stack)

                if csharp_messaging:
                    with st.expander("View .NET RabbitMQ/MassTransit signals"):
                        for item in csharp_messaging[:25]:
                            match_text = ", ".join(item.get("matches", []))
                            st.text(f"‚Ä¢ {item['file']} ({match_text})")

                if node_messaging:
                    with st.expander("View Node.js RabbitMQ signals"):
                        for item in node_messaging[:25]:
                            match_text = ", ".join(item.get("matches", []))
                            st.text(f"‚Ä¢ {item['file']} ({match_text})")

                if angular_files:
                    with st.expander("View Angular files detected"):
                        for item in angular_files[:25]:
                            st.text(f"‚Ä¢ {item['file']}")

                st.caption(
                    "Signals are inferred from imports/usings and file paths. "
                    "Review the file lists to confirm actual integrations."
                )

                st.markdown("---")

                # Metrics
                st.markdown("#### üìä Analysis Metrics")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Total Files", analysis['file_count'])
                with col2:
                    st.metric("Total Classes", analysis['class_count'])
                with col3:
                    st.metric("Dependencies", analysis['dependency_count'])
                with col4:
                    st.metric("External Deps", analysis['external_dependency_count'])
                
                st.markdown("---")
                
                # Visual Dependency Graph
                st.markdown("#### üó∫Ô∏è Dependency Graph")
                
                # Generate Mermaid diagram
                if dep_map and len(dep_map.get('edges', [])) > 0:
                    mermaid_code = "graph TD\n"
                    
                    # Normalize paths to handle Windows/Unix differences and GitHub paths
                    def normalize_path(path_str: str) -> str:
                        """Normalize path string to handle different separators"""
                        if not path_str:
                            return ""
                        # Convert to Path and back to string to normalize separators
                        try:
                            # Handle both absolute and relative paths
                            p = Path(path_str)
                            # Use as_posix() to normalize to forward slashes
                            return p.as_posix()
                        except:
                            # Fallback: just replace backslashes
                            return str(path_str).replace('\\', '/')
                    
                    # Build a mapping of all node IDs (normalized) to their sanitized Mermaid IDs
                    all_node_map = {}
                    for node in dep_map['nodes']:
                        # Normalize the path before using it
                        normalized_id = normalize_path(node['id'])
                        normalized_path = normalize_path(node['path'])
                        # Use normalized path for sanitization
                        node_id = sanitize_mermaid_node_id(normalized_path)
                        # Map both original and normalized IDs to the sanitized node ID
                        all_node_map[normalized_id] = node_id
                        all_node_map[node['id']] = node_id  # Also keep original for backward compatibility
                        all_node_map[node['path']] = node_id  # Also map by path
                    
                    # Collect nodes referenced in edges (limit to 100 edges for performance)
                    edges_to_show = dep_map['edges'][:100]
                    referenced_nodes = set()
                    for edge in edges_to_show:
                        normalized_source = normalize_path(edge['source'])
                        normalized_target = normalize_path(edge['target'])
                        if normalized_source in all_node_map:
                            referenced_nodes.add(normalized_source)
                        if normalized_target in all_node_map:
                            referenced_nodes.add(normalized_target)
                    
                    # Build node_ids mapping for referenced nodes
                    node_ids = {}
                    for node in dep_map['nodes']:
                        normalized_id = normalize_path(node['id'])
                        if normalized_id in referenced_nodes or len(referenced_nodes) == 0:
                            if normalized_id in all_node_map:
                                node_ids[normalized_id] = all_node_map[normalized_id]
                                # Also map original IDs for compatibility
                                node_ids[node['id']] = all_node_map[normalized_id]
                    
                    # Add edges
                    edges_added = set()
                    for edge in edges_to_show:
                        # Normalize source and target paths
                        source_id = normalize_path(edge['source'])
                        target_id = normalize_path(edge['target'])
                        
                        # Check if both nodes exist in our mapping
                        if source_id in node_ids and target_id in node_ids:
                            source_label = node_ids[source_id]
                            target_label = node_ids[target_id]
                            edge_key = f"{source_label}->{target_label}"
                            
                            if edge_key not in edges_added:
                                # Sanitize labels properly - handle both relative and absolute paths
                                try:
                                    source_path = Path(edge['source'])
                                    target_path = Path(edge['target'])
                                    source_name = sanitize_mermaid_label(source_path.stem if source_path.stem else source_path.name)
                                    target_name = sanitize_mermaid_label(target_path.stem if target_path.stem else target_path.name)
                                except:
                                    # Fallback: use the path string directly
                                    source_name = sanitize_mermaid_label(str(edge['source']).split('/')[-1].split('\\')[-1])
                                    target_name = sanitize_mermaid_label(str(edge['target']).split('/')[-1].split('\\')[-1])
                                
                                mermaid_code += f'  {source_label}["{source_name}"] --> {target_label}["{target_name}"]\n'
                                edges_added.add(edge_key)
                    
                    if MERMAID_AVAILABLE:
                        try:
                            stmd.st_mermaid(mermaid_code)
                        except Exception as e:
                            st.warning(f"‚ö†Ô∏è Could not render diagram: {str(e)}")
                            with st.expander("View diagram code"):
                                st.code(mermaid_code, language="mermaid")
                    else:
                        st.info("üí° Install streamlit-mermaid to view diagrams: `pip install streamlit-mermaid`")
                        with st.expander("View diagram code"):
                            st.code(mermaid_code, language="mermaid")
                else:
                    st.info("No dependencies found to visualize.")
                
                st.markdown("---")
                
                # Circular Dependencies
                if analysis.get('circular_dependencies'):
                    st.markdown("#### ‚ö†Ô∏è Circular Dependencies")
                    st.warning(f"Found {len(analysis['circular_dependencies'])} circular dependency cycle(s)")
                    for idx, cycle in enumerate(analysis['circular_dependencies'][:10], 1):
                        cycle_path = " ‚Üí ".join([Path(f).name for f in cycle])
                        st.code(f"Cycle {idx}: {cycle_path}")
                
                # Orphaned Files
                if analysis.get('orphaned_files'):
                    st.markdown("#### üì¶ Orphaned Files")
                    st.info(f"Found {len(analysis['orphaned_files'])} file(s) with no dependencies")
                    with st.expander("View orphaned files"):
                        for file_path in analysis['orphaned_files'][:20]:
                            st.text(f"‚Ä¢ {file_path}")
                
                # Highly Coupled Files
                if analysis.get('highly_coupled_files'):
                    st.markdown("#### üîó Highly Coupled Files")
                    st.info("Files with high coupling (many dependencies or dependents)")
                    
                    # Create a table
                    try:
                        import pandas as pd
                        coupled_data = []
                        for item in analysis['highly_coupled_files'][:15]:
                            coupled_data.append({
                                'File': Path(item['file']).name,
                                'Dependencies': item['dependencies'],
                                'Dependents': item['dependents'],
                                'Total Coupling': item['total_coupling']
                            })
                        
                        if coupled_data:
                            df = pd.DataFrame(coupled_data)
                            st.dataframe(df, use_container_width=True, hide_index=True)
                    except ImportError:
                        st.info("Install pandas for table view: `pip install pandas`")
                        for item in analysis['highly_coupled_files'][:15]:
                            st.text(f"‚Ä¢ {Path(item['file']).name}: {item['total_coupling']} total coupling")
                
                st.markdown("---")
                
                # Export Options
                st.markdown("#### üíæ Export Dependency Map")
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    if st.button("üìÑ Export JSON", use_container_width=True, key="export_json"):
                        if 'dependency_analyzer' in st.session_state:
                            with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as tmp:
                                output_file = st.session_state.dependency_analyzer.export_json(tmp.name)
                                with open(output_file, 'r') as f:
                                    json_data = f.read()
                                st.download_button(
                                    label="üì• Download JSON",
                                    data=json_data,
                                    file_name="dependency_map.json",
                                    mime="application/json",
                                    use_container_width=True,
                                    key="dl_json"
                                )
                
                with col2:
                    if st.button("üîÑ Export DOT", use_container_width=True, key="export_dot"):
                        if 'dependency_analyzer' in st.session_state:
                            with tempfile.NamedTemporaryFile(mode='w', suffix='.dot', delete=False) as tmp:
                                output_file = st.session_state.dependency_analyzer.export_dot(tmp.name)
                                with open(output_file, 'r') as f:
                                    dot_data = f.read()
                                st.download_button(
                                    label="üì• Download DOT",
                                    data=dot_data,
                                    file_name="dependency_map.dot",
                                    mime="text/plain",
                                    use_container_width=True,
                                    key="dl_dot"
                                )
                
                with col3:
                    if st.button("üåä Export Mermaid", use_container_width=True, key="export_mermaid"):
                        if 'dependency_analyzer' in st.session_state:
                            with tempfile.NamedTemporaryFile(mode='w', suffix='.mmd', delete=False) as tmp:
                                output_file = st.session_state.dependency_analyzer.export_mermaid(tmp.name)
                                with open(output_file, 'r') as f:
                                    mermaid_data = f.read()
                                st.download_button(
                                    label="üì• Download Mermaid",
                                    data=mermaid_data,
                                    file_name="dependency_map.mmd",
                                    mime="text/plain",
                                    use_container_width=True,
                                    key="dl_mermaid"
                                )
                
                with col4:
                    if st.button("üìù Export Markdown", use_container_width=True, key="export_md"):
                        if 'dependency_analyzer' in st.session_state:
                            markdown_report = st.session_state.dependency_analyzer.generate_markdown_report()
                            st.download_button(
                                label="üì• Download Markdown",
                                data=markdown_report,
                                file_name="dependency_map.md",
                                mime="text/markdown",
                                use_container_width=True,
                                key="dl_md"
                            )
        else:
            st.info("üëÜ Please select and process source code first in the 'Source Selection' and 'Generate' tabs.")
            st.markdown("""
            **How to use Dependency Map:**
            1. Go to **Source Selection** tab and select your source code
            2. Go to **Generate** tab and click "Generate Documentation" (this will read your files)
            3. Come back to this tab and click "Analyze Dependencies"
            4. View the interactive dependency graph and analysis results
            """)
    
    # Footer
    st.markdown("---")
    st.markdown(
        "<div style='text-align: center; color: #6b7280; padding: 2rem;'>"
        "<strong>TechDocGen by IBMC</strong> - Powered by AI | Support: Java, .NET (C#, VB.NET, F#), PHP"
        "</div>",
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()

